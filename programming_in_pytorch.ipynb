{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6SGZ-S2n7MP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0250e62c-6744-4f33-ffb0-aa9da22473dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-k18r4QpOz_"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LJ0xPsi1poT3",
        "outputId": "4f2cc115-c32f-4096-c961-b9dfa61c7d1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1yW8SLJMtTn",
        "outputId": "cfa32149-a41c-49eb-d0ea-035f8fc8bb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DrIgtqhcVVk",
        "outputId": "19344700-0014-42d4-d7c7-186048f00127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rough for revision\n",
        "import numpy as np\n",
        "\n",
        "torch.tensor([[1,2,3]], device = \"cpu\").numpy()\n",
        "\n",
        "torch.from_numpy(np.array([1,2,3]))\n",
        "\n",
        "# Torch tenosrs can be converted into numpy arrays and vice versa with a catch that\n",
        "# if the the torch tensor is on cuda/gpu it can not be converted into numpy array.\n",
        "# torch tensors can be converted into numpy array by merely calling numpy() method\n",
        "# on it i.e a.numpy(), while a numpy array a can be coverted into torch tensor as\n",
        "# follows: torch.from_numpy(a)\n",
        "\n",
        "# now a torch tensor or a model can be sent to the assigned device whether gpu or cpu\n",
        "# by merely uisng to(device) command where device is alredy defined either as cpu or\n",
        "# gpu using the command torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# let me learn some operations on torch tensors\n",
        "\n",
        "# addition, substraction, point wise multiplication and division is as usual.\n",
        "tensor1 = torch.tensor([[1, 2, 3], [5, 6, 7]])\n",
        "transpose = tensor1.t()\n",
        "\n",
        "# matrix multiplication\n",
        "tensor2 = torch.tensor([[1, 2],[3, 4], [5, 6]])\n",
        "tensor1.matmul(tensor2)\n",
        "\n",
        "# sum of all elements\n",
        "torch.sum(tensor1)\n",
        "\n",
        "# sum along axis\n",
        "torch.sum(tensor1, axis = 0) # sum along rows, i.e picks individual columns and sum its elements\n",
        "\n",
        "torch.sum(tensor1, axis = 1) # sum along columns, i.e picks individual rows and sum its elements\n",
        "\n",
        "# slicing, broadcasting is similar to numpy\n",
        "\n",
        "# shape of a tensor ( two ways)\n",
        "tensor1.shape\n",
        "tensor1.size()\n",
        "\n",
        "tensor1.shape == tensor1.size() # the answer is True\n",
        "\n",
        "# specifying datatype inside a tensor\n",
        "\n",
        "torch.tensor([[1, 2, 3], [5, 6, 7]], dtype = torch.float)\n",
        "torch.tensor([[1.0, 2.0, 3.0], [5.0, 6.0, 7.0]], dtype = torch.int32)\n",
        "\n",
        "\n",
        "# random number generation using torch\n",
        "\n",
        "# uniform (0,1)\n",
        "torch.rand(2,3) # generate a random unifrom sample of the shape (2,3)\n",
        "\n",
        "# normal\n",
        "torch.randn(2, 3)\n",
        "\n",
        "# generating random integer with specified range\n",
        "\n",
        "# Generating a 2x3 random tensor with integers between 0 and 9\n",
        "torch.randint(0, 10, (2, 3))\n",
        "\n",
        "\n",
        "x = torch.tensor([1.0, 2.0], requires_grad = True)\n",
        "z = x**2\n",
        "z.backward(torch.tensor([3.0, 3.0]))\n",
        "w = z.detach()\n",
        "x.grad\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFhm_5nWDkVw",
        "outputId": "0703eea5-1316-4c56-dab0-f00cb2e3b3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enJvqLtTpqMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5819a37f-70dc-4a86-f1a3-697789e79cf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Creating an empty tensor\n",
        "x = torch.empty(3)\n",
        "y = torch.empty((3, 5))\n",
        "# Basically torch.empty((3, 5)) and torch.empty(3, 5) aren't dfferent\n",
        "x.to(device)\n",
        "z = torch.ones(5, device = device)\n",
        "z.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhnsv_RttBjR",
        "outputId": "23363f96-f5eb-479d-d5c5-6c9350fad1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1.0524e-37)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0524e-37,  3.0878e-41,  1.4013e-45,  0.0000e+00, -1.0524e-37],\n",
              "        [ 3.0878e-41, -1.0524e-37,  3.0878e-41,  3.3631e-44,  2.9427e-44],\n",
              "        [-2.1368e-04,  4.4843e-41,  2.8026e-45,  4.4843e-41,  0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(y[0][0])\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q15diGInqQHr",
        "outputId": "560c4fba-aa8b-49ab-b074-b3968269e443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "y.shape\n",
        "print(torch.empty(3,5).shape)\n",
        "torch.empty((3,5)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrGtGAGztAOf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caBXbmNIqRzB",
        "outputId": "3cfd2c9c-1f4e-43e7-94c7-71956993f505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "torch.zeros(4, 6)\n",
        "torch.ones((2,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJRXOPIBr1C2"
      },
      "outputs": [],
      "source": [
        "z = torch.zeros((3,2), dtype = torch.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJpiXoJ-sKDH",
        "outputId": "8d51c474-7abd-4612-afe9-e222d6ce31b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-478c7aaee7a2>:3: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  w = torch.tensor([1.0, 2.0, 3.0], dtype = torch.int32)\n"
          ]
        }
      ],
      "source": [
        "# Now this is how we create a general tensors\n",
        "\n",
        "w = torch.tensor([1.0, 2.0, 3.0], dtype = torch.int32)\n",
        "\n",
        "# This also teaches us one thing if we specify the dtype, it converts to the given data type if possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX67mJN47Q4K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuJIJzIHsTR1",
        "outputId": "2a059b5c-960a-4d15-e445-9af5ec156673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3], dtype=torch.int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "print(w)\n",
        "\n",
        "r = torch.tensor([1,2,4], dtype = torch.float32)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLTrRf4ytfib"
      },
      "outputs": [],
      "source": [
        "# Random values\n",
        "\n",
        "a = torch.rand(2,2)\n",
        "b = torch.rand(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnx1yg6MuFK3",
        "outputId": "341aad69-0080-4bb3-cba3-44968c1c9576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.3090, 0.7030],\n",
            "        [0.8220, 0.9496]])\n",
            "tensor([[1.3090, 0.7030],\n",
            "        [0.8220, 0.9496]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3090, 0.7030],\n",
              "        [0.8220, 0.9496]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# a+b will do the elementwise addition of the tensors a and b, another way to do it is a.add(b), if i want to do the inplace addition ie the\n",
        "# value of a should be replaced by a+b, then the command for that is a.add_(b), lets try the last one too\n",
        "\n",
        "print(a.add(b))\n",
        "print(a.add_(b))\n",
        "a\n",
        "\n",
        "# Things are working as expected, everytime i am running it it add b agains so in the n time\n",
        "# it wil throw a+nb, as a is basically updated to a+(n-1)b in the (n-1)th iterarion\n",
        "\n",
        "# Also every function that has a trailing undercore like add_ will do an inplace operation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oL5F36YuFuG",
        "outputId": "e3d63899-d383-4007-ed63-26ae77347ab5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5963, 0.1422],\n",
              "        [0.7237, 0.8534]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Substraction (point wise)\n",
        "a - b\n",
        "a.sub_(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL1yTfXyvhAx",
        "outputId": "e6f71d10-7dfd-40da-9d74-02bc927305f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4250, 0.0797],\n",
            "        [0.0712, 0.0821]])\n",
            "tensor([[0.4250, 0.0797],\n",
            "        [0.0712, 0.0821]])\n",
            "tensor([[0.4250, 0.0797],\n",
            "        [0.0712, 0.0821]])\n"
          ]
        }
      ],
      "source": [
        "# Multiplication (point wise)\n",
        "\n",
        "print(a*b)\n",
        "print(a.mul(b))\n",
        "print(a.mul_(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQWAYCidvoMr",
        "outputId": "73537c3d-e316-443f-fc3f-434bcb2ba27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4250, 0.0797],\n",
            "        [0.0712, 0.0821]])\n",
            "tensor([[0.7127, 0.5608],\n",
            "        [0.0984, 0.0962]])\n",
            "tensor([[0.5963, 0.1422],\n",
            "        [0.7237, 0.8534]])\n",
            "tensor([[0.5963, 0.1422],\n",
            "        [0.7237, 0.8534]])\n",
            "tensor([[0.5963, 0.1422],\n",
            "        [0.7237, 0.8534]])\n"
          ]
        }
      ],
      "source": [
        "# Division (point wise)\n",
        "print(a)\n",
        "print(b)\n",
        "print(a/b)\n",
        "print(a.div(b))\n",
        "print(a.div_(b)) # recall : a will be replaced by a/b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5113An8upqF",
        "outputId": "b16b164b-be1f-4d72-9d8d-59a6894a7915"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 4, 6],\n",
              "        [3, 5, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# I am checking broadcasting\n",
        "\n",
        "a = torch.tensor([[1,2,3], [2,3,4]])\n",
        "a + torch.tensor([1,2,3])\n",
        "\n",
        "# I have tried different broadcasting features, it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtRE59-Qv0wI",
        "outputId": "ddf5b5c2-cf07-4794-95e9-dfa601e94637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3681, 0.9339, 0.6253],\n",
            "        [0.2650, 0.6916, 0.1364],\n",
            "        [0.6939, 0.0182, 0.1252],\n",
            "        [0.4222, 0.0913, 0.7349],\n",
            "        [0.0265, 0.8365, 0.4312]])\n",
            "torch.Size([5])\n",
            "tensor(0.1364)\n",
            "tensor([0.2650, 0.6916, 0.1364])\n"
          ]
        }
      ],
      "source": [
        "# Tensor slicing is same as numpy, basically a[1, 2] gives the\n",
        "# item in the row number 1 (infact 2 as starts with 0) and column\n",
        "# number 3, a[:, 1] will give column number 1 but the output\n",
        "# will be a row vector\n",
        "\n",
        "d = torch.rand(5,3)\n",
        "print(d)\n",
        "print(d[:, 1].shape)\n",
        "print(d[1,2])\n",
        "print(d[1, :])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMWbvLCkv8Tw",
        "outputId": "34885ecf-0345-435f-82e1-2a42d6c5f764"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3],\n",
              "        [ 2,  3, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# I remeber that in tesnorflow i can not assign assign element by simply writing a[1,2] = 5, which i needed there was a[1,2].assign(5),\n",
        "# let me try to check my memory here and also see if we can do simple assignments in torch\n",
        "\n",
        "import tensorflow as tf\n",
        "ta = tf.Variable([[1,2,3], [2,3,4]])\n",
        "ta[1,2].assign(10)\n",
        "ta\n",
        "\n",
        "# Now we try in pytorch\n",
        "\n",
        "a\n",
        "a[1,2] = 10\n",
        "a\n",
        "\n",
        "# So in pytorch the assignment is same as that of numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmo5_HP6woq7",
        "outputId": "28298c8a-fac7-4018-c7a7-ed7d3217f99e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1363844871520996"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# if we have only one value in the tensor, we can use\n",
        "# .item() to take out the value, but be careful this\n",
        "# can be used only when we have one value in the tensor\n",
        "\n",
        "d[1,2].item() # this is a plain number, no relation with torch now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgFo_CawxSm1",
        "outputId": "fa6ccccf-744d-406b-b93e-5ced6cd1157c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 6])\n",
            "torch.Size([4, 6])\n",
            "tensor([[0.2326, 0.1312, 0.3143],\n",
            "        [0.8972, 0.4192, 0.7101],\n",
            "        [0.0406, 0.9830, 0.8718],\n",
            "        [0.8996, 0.8585, 0.5530],\n",
            "        [0.6777, 0.5854, 0.3515],\n",
            "        [0.0849, 0.5016, 0.9098],\n",
            "        [0.0989, 0.1796, 0.3558],\n",
            "        [0.5717, 0.0582, 0.8489]])\n",
            "tensor([[0.2326, 0.1312],\n",
            "        [0.3143, 0.8972],\n",
            "        [0.4192, 0.7101],\n",
            "        [0.0406, 0.9830],\n",
            "        [0.8718, 0.8996],\n",
            "        [0.8585, 0.5530],\n",
            "        [0.6777, 0.5854],\n",
            "        [0.3515, 0.0849],\n",
            "        [0.5016, 0.9098],\n",
            "        [0.0989, 0.1796],\n",
            "        [0.3558, 0.5717],\n",
            "        [0.0582, 0.8489]])\n",
            "tensor([[0.2326, 0.1312, 0.3143, 0.8972, 0.4192, 0.7101, 0.0406, 0.9830],\n",
            "        [0.8718, 0.8996, 0.8585, 0.5530, 0.6777, 0.5854, 0.3515, 0.0849],\n",
            "        [0.5016, 0.9098, 0.0989, 0.1796, 0.3558, 0.5717, 0.0582, 0.8489]])\n"
          ]
        }
      ],
      "source": [
        "# Reshaping a tensor in torch, but before we do that i will just add how we used to do that in tensorflow too\n",
        "\n",
        "# Tensorflow\n",
        "# import tensorflow as tf\n",
        "# tfa = tf.Variable([1,2,3,4,5,6])\n",
        "# tf.reshape(tfa, (3,2))\n",
        "\n",
        "# Pytorch\n",
        "pya = torch.rand(4,6)\n",
        "\n",
        "# First of all the size can be printed in various ways\n",
        "\n",
        "print(pya.shape)\n",
        "print(pya.size())\n",
        "\n",
        "# both above ways give the same result\n",
        "\n",
        "pyb = pya.view(24)\n",
        "\n",
        "pyb = pya.view(8, -1)\n",
        "\n",
        "pyc = pya.view(-1, 2)\n",
        "\n",
        "print(pyb)\n",
        "print(pyc)\n",
        "\n",
        "print(pya.view(3, 8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vYTvYYqxrOO",
        "outputId": "d0b3d628-b2a9-4a0d-9512-7fa706827997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Let's explore how numpy as torch interects\n",
        "import torch\n",
        "import numpy as np\n",
        "a = torch.ones(5)\n",
        "b = a.numpy()\n",
        "type(b)\n",
        "\n",
        "# Note: If the code is running on GPU and not CPU, then\n",
        "# a and b maps to same memory location, so if i make change\n",
        "# to a it will reflect in b as well, for example\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "# Great, as stated the array is same, one is pytorch array and the other is numpy array but they are identical\n",
        "\n",
        "\n",
        "# Update: Upon new attempt i found that if a is a GPU tensor then it can't be converted to numpy,\n",
        "# it gives the error \"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pkt = torch.tensor([1.2, 2.3, 3.4])\n",
        "pkt = pkt.to(device)\n",
        "# so the leanring is that just pkt.to(device) would not send pkt to cuda rather it makes a copy of pkt on cuda to you need to assign pkt pkt.to(device)\n",
        "print(pkt)\n",
        "print(pkt.is_cuda)\n",
        "print(pkt.cpu().numpy()) # so a cuda tensor can not be converted into numpy array,\n",
        "# it needs to be sent to cpu first which can be done by tnsr.cpu() where tnsr is the torch tensor\n",
        "\n",
        "pkn = pkt.cpu().numpy()\n",
        "\n",
        "pkt.add_(1)\n",
        "print(pkt)\n",
        "print(pkn)\n",
        "\n",
        "# obsrvation: if we change pkt using pkt.add_(1) and pkt is cpu tensor, the chnage would reflect in pkn as well.\n",
        "# No change would reflect on pkn if it is cuda tensor or we make change using command pkt = pkt+1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZAY366Ygpe9",
        "outputId": "d8c0ba7a-0167-4ba7-d495-d453d878abb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2000, 2.3000, 3.4000], device='cuda:0')\n",
            "True\n",
            "[1.2 2.3 3.4]\n",
            "tensor([2.2000, 3.3000, 4.4000], device='cuda:0')\n",
            "[1.2 2.3 3.4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zuq60oXy4Fef",
        "outputId": "1e76b1a5-6d2c-4556-fcc0-7ae36d27e7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 2.]\n",
            " [2. 2.]\n",
            " [2. 2.]\n",
            " [2. 2.]\n",
            " [2. 2.]]\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], device='cuda:0', dtype=torch.float64)\n",
            "cuda:0\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Now we learn how to convert a numpy array into the torch tensor\n",
        "a = np.ones((5,2))\n",
        "\n",
        "b = torch.from_numpy(a)\n",
        "# b = b.to(device)\n",
        "# Now let me test for the memory allocation\n",
        "\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(b.device)\n",
        "print(device)\n",
        "\n",
        "# when i make b a GPU tensor then a and b are different, b doesn't get updated with\n",
        "# change in a, but if we make b as cpu tensor then b will also get updated. Another update a = a + 1 make a new tensor while a += 1\n",
        "# means make change to a at the same location, so this experiment works when a += 1 is done not when a = a + 1 is performed.\n",
        "# Thus when numpy array is on cpu and the corresponding torch tenosr is also on cpu then a += 1 will reflect in the torch tensor and vice versa\n",
        "# which means is a is a torch tensor on cpu and b = a.numpy() and a+=1 is performed then b will also be impacted. Also, in either case if a and b\n",
        "# are numpy and torch tensor formed by from_numpy or .numpy() operation then they are connected and changes in one would reflect on other.\n",
        "# Now torch tensor on cuda can not be converted into numpy array directly so no such question but when opposite happens like numpy array\n",
        "# is converted into tenosr and then  sent to device then done expect change in numpy guy to be reflected in torch guy. In summary\n",
        "# the sending to cuda process creates tensor at another location and thus will break the connection. Like when i create a numpy\n",
        "# array a = np.array([1,2,3]) its on cpu similar for torch tensor thus its easy to connect these guys to reflect the chnages of\n",
        "# one another into the other, while when one is sent on gpu's vram its not possible .\n",
        "\n",
        "# overall, when on cpu the tensors are mapped to one object so changing one will change other but if it's a cuda tensor, they would be different"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YweFC11x5uaD"
      },
      "outputs": [],
      "source": [
        "# Also note, numpy can not handle GPU tensors, so if i have a GPU torch tenosr and i want to convet it\n",
        "# into numpy by .numpy() command it wont work, so the tensor first need to be converted to CPU tensor using command t.cpu()\n",
        "# and the only i can convert it to numpy as proceed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8wZz-13-fyd"
      },
      "outputs": [],
      "source": [
        "# Now, similar to varaible in the tensorflow, there is a concept here too, but here within the tensor itself,\n",
        "# we specify requires_grad to True, which is by default false, this lets the system know that we may compute\n",
        "# the gradient for these in future\n",
        "\n",
        "a = torch.tensor([1.0, 2.0, 3.0], requires_grad= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTyiKWrB-39z",
        "outputId": "c4d7e0e9-14b2-418d-d489-0e7645afaae8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgXRRmTe-4Rm"
      },
      "outputs": [],
      "source": [
        "# Now we will learn how to find gradients in pytorch, this tool is USP of hardcore packages like tensorflow and pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efMgFPa908qA",
        "outputId": "905aeb3a-583b-4344-ceed-2c3c91fca0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6853,  1.0300,  0.5914], requires_grad=True)\n",
            "tensor([1.3147, 3.0300, 2.5914], grad_fn=<AddBackward0>)\n",
            "tensor([ 3.4571, 18.3623, 13.4302], grad_fn=<MulBackward0>)\n",
            "tensor(11.7499, grad_fn=<MeanBackward0>)\n",
            "tensor([1.7530, 4.0401, 3.4551])\n"
          ]
        }
      ],
      "source": [
        "# Lets create a tensor x, with respect to which i will be finding the gradient\n",
        "\n",
        "x = torch.randn(3, requires_grad= True)\n",
        "\n",
        "y = x+2\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "z = 2*(y**2)\n",
        "\n",
        "w = torch.mean(z)\n",
        "\n",
        "print(z)\n",
        "print(w)\n",
        "w.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al954tLO1gyd",
        "outputId": "3eed5d0a-8639-4251-9e0d-e02f05c74185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9906,  1.4166, -1.4822], requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.6604,  0.9444, -0.9881])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Lets do the gradient finding in pytorch again\n",
        "\n",
        "x = torch.randn(3, requires_grad = True)\n",
        "y = x**2\n",
        "z = y.mean()\n",
        "\n",
        "# Basically, in a layman language pytorch has made the computational graph starting from x and then to y and\n",
        "# then to z, so when we print y, one arg is grad_fn whose value is powbackward, in z the grad_fn is mean_backward,\n",
        "# so basically pytorch now knows that when the gradient of z is demanded it should move backward by mean to find\n",
        "# grd wrt y and then move backward by gradient for power to get from y to x and basiaclly using chain rule it can\n",
        "# multiply both graidents to throw the gradient of z wrt x\n",
        "\n",
        "# So in order to trigger this backpropagation to compute the gradient, what we do is; run the command z.backward()\n",
        "# and then we can print the gradient wrt x by x.grad, lets try it\n",
        "\n",
        "z.backward()\n",
        "print(x)\n",
        "x.grad\n",
        "\n",
        "# Yeah this seems to work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRHys0JR1hPr",
        "outputId": "d6e3eeb0-798b-42ff-d07c-f04f1f91095e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6140, -0.3155, -1.3784], requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7993, -0.2840, -1.6297])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Now what i want to try is write a function of x and then specify x and z and find the gradient,\n",
        "\n",
        "def f(x):\n",
        "  return(((torch.sin(x))**2 + 2*(x**2) + x).mean())\n",
        "\n",
        "x = torch.randn(3, requires_grad = True)\n",
        "z = f(x)\n",
        "\n",
        "print(x)\n",
        "z.backward()\n",
        "x.grad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxA5rDu-nWp5",
        "outputId": "d565555a-9d53-4bc5-fe64-d88ea5a7ad58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 2.5455637,  1.5449096, -1.3266551], dtype=float32)>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "x = tf.Variable([ 1.7441,  0.6658, -1.0226])\n",
        "\n",
        "\n",
        "def g(x):\n",
        "  return (tf.reduce_mean(tf.square(tf.math.sin(x)) + 2*tf.square(x) + x))\n",
        "\n",
        "with tf.GradientTape(persistent= True) as tape:\n",
        "  z = g(x)\n",
        "\n",
        "tape.gradient(z, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62p5bTrgqX5O"
      },
      "outputs": [],
      "source": [
        "# So what we observe is both of them work equally good, what next i want to figure out is how does converting\n",
        "# one torch fn into tensorflow function and tensorflow function into torch fn and also the varibles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAkq-lSBvXil",
        "outputId": "ceed53fb-1f44-4cee-cdd6-449715c2f1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0.15886523 -0.13268454  0.19663806], shape=(3,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.017605187>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.004144926>]\n",
            "tf.Tensor([-0.02609083 -0.23413014 -0.02107896], shape=(3,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# The output was a scalar in the above case, what if it's a vector too, in that case the output should be a m, n matrix is the map goes from R^n to R^m\n",
        "# Lets try it, first tensorflow\n",
        "\n",
        "x = tf.random.normal([3])\n",
        "with tf.GradientTape(persistent = True) as tape:\n",
        "  tape.watch(x)\n",
        "  z = [tf.Variable(1.0), x[1]**2, x[0]*x[1]*x[2]]\n",
        "\n",
        "print(x)\n",
        "print(z)\n",
        "print(tape.gradient(z, x))\n",
        "\n",
        "# So what i observe is that it gives the number of outputs same as number of inputs, and what it does is it will find the derivative of all the f_i wrt to that particular input and sum that up ans that would be the output, i.e it is tf.reduce_sum(jacobian, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just testing my memory by using both the tf gradient and torch gradient\n",
        "\n",
        "import tensorflow as tf\n",
        "atf = tf.Variable([0.1, 2.3, 3.1])\n",
        "\n",
        "def tffn(x):\n",
        "  return tf.reduce_mean(tf.sin(x)+tf.square(x+1)*tf.cos(x))\n",
        "\n",
        "with tf.GradientTape(persistent = True) as tape:\n",
        "  z = tffn(atf)\n",
        "\n",
        "print(tape.gradient(z, atf))\n",
        "\n",
        "# lets do it using pytorch\n",
        "ator = torch.tensor([0.1, 2.3, 3.1], requires_grad = True)\n",
        "\n",
        "def torfn(x):\n",
        "  return torch.mean(torch.sin(x) + torch.cos(x)*torch.square(x+1))\n",
        "\n",
        "w = torfn(ator)\n",
        "w.backward()\n",
        "print(ator.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0-jI275IiCF",
        "outputId": "56a9e150-0282-4d44-a05d-057e119ac315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 1.0210717 -4.3948092 -3.2970054], shape=(3,), dtype=float32)\n",
            "tensor([ 1.0211, -4.3948, -3.2970])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrNwHf_av6Wh",
        "outputId": "71ed25bc-7797-4e51-c93b-ed35562783e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, -0.0000, 2.4395])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "\n",
        "x = torch.randn(3, requires_grad = True)\n",
        "z = torch.square(x)\n",
        "\n",
        "z1 = torch.tensor([1, 0, 0])\n",
        "z2 = torch.tensor([0, 1, 0])\n",
        "z3 = torch.tensor([0, 0, 1])\n",
        "\n",
        "z.backward(z3)\n",
        "x.grad\n",
        "\n",
        "# How the torch works is, in that case it takes a vector v as input to thr z.backward(v) and the returns the jacobian*v as the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0x230pf91Ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2965253d-0e11-4e93-a942-2cc14a5311bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.)\n",
            "tensor(8.)\n"
          ]
        }
      ],
      "source": [
        "# One more concept\n",
        "x = torch.tensor(2.0, requires_grad = True)\n",
        "y = x**2\n",
        "z = 2*y\n",
        "\n",
        "\n",
        "# if i do y.backward() and compute x.grad it would be 4, if i do z.backward()\n",
        "# and compute x.grad it would be 8, what if i do both. Firstly it wont happen\n",
        "# there will be error saying the computation graph was killed after first backward\n",
        "# move, so if we still want to reatin computation graph make y.backward(retain_graph = True)\n",
        "# and then i can again do z.backward() or vice versa. But if we do both what would be x.grad,\n",
        "# it would be sum of both dy/dx + dz/dx, lets try\n",
        "\n",
        "z.backward(retain_graph = True)\n",
        "print(x.grad)\n",
        "\n",
        "\n",
        "# if i dont want to add gradient on top of already computed one, i can make the gradient 0 by x.grad.zero_(), let try it\n",
        "x.grad.zero_()\n",
        "z.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omoKh4JMyXke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad091eee-1c30-44c4-f109-12cf4dec86fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([0.4455, 0.6560, 1.5768], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Now we learn how to prevent pytorch to compute the gradient\n",
        "\n",
        "# There are three ways; 1) set x.requires_grad_(False) or x.detach() will create new tensor for which\n",
        "# requires_grad would be false and the third was is with torch.no_grad(): and then write things below\n",
        "# it, lets see how this can be done\n",
        "\n",
        "# x = torch.randn(3, requires_grad = True)\n",
        "# print(x)\n",
        "# x.requires_grad_(False)\n",
        "# print(x)\n",
        "# We can see that x now does not have requires_grad within it\n",
        "\n",
        "# x = torch.randn(3, requires_grad = True)\n",
        "# y = x.detach()\n",
        "# print(y)\n",
        "# We can see that y does not have requires_grad within it\n",
        "\n",
        "x = torch.randn(3, requires_grad = True)\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "\n",
        "# y.backward() # this wont work as torch was not expected to createe the computational graph so not it can not do the backward operation\n",
        "print(x.grad)\n",
        "print(x)\n",
        "# We can see that y does not have requires_grad within it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87Jwsi1C0OgS",
        "outputId": "6d60cf46-f889-44e1-f329-173c865a38c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Another thing to note is that if my x is the input and it is used to generate multiple outputs z1, z2, z3 and\n",
        "# so on and we kept on invoking the command z1.backward(), z2.backward() and z3.backward() then these individual\n",
        "# gradients will keep on accumulting (adding) in x.grad, in other words x.grad = dz1_dx + dz2_dx + dz3_dx, in order\n",
        "# to reset the grads to zero we can run the command x.grad.zero_(), one point to note that if z1, z2, z3 have an\n",
        "# intersection in the computationa graph, then keep using retain_graph = True everytime we call backward, else the\n",
        "# graph would expire after the first backward call\n",
        "\n",
        "# Just an example to illustrate this is:\n",
        "\n",
        "weights = torch.ones(4, dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "for epochs in range(3):\n",
        "  model_output = (3*weights).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "weights = torch.ones(4, dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "for epochs in range(3):\n",
        "  model_output = (3*weights).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9QvRc5Y7_2P"
      },
      "outputs": [],
      "source": [
        "# Now we will build linear regression from scratch using pytorch and then later will automate it using the torch packages, lets build it from scratch here\n",
        "\n",
        "# First every thing manually using the numpy\n",
        "\n",
        "# Let X be the input data of shape n, p where n is the number of instance and p is the number of covariates, and y be the label of shape n,1\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegression:\n",
        "  def __init__(self, X, y):\n",
        "    self.y = y\n",
        "    self.n = X.shape[0]\n",
        "    self.p = X.shape[1]\n",
        "    self.X = np.array([[1.0]*(self.n)]+ list(X.T)).T\n",
        "    self.weights = np.random.normal(0,1, self.p+1).reshape((-1, 1))\n",
        "    self.learning_rate = 0.001\n",
        "    self.n_iter = 5000\n",
        "\n",
        "  def forward_pass(self):\n",
        "    return (np.matmul(self.X, self.weights))\n",
        "\n",
        "  def mse_loss(self):\n",
        "    y_pred = self.forward_pass()\n",
        "    return np.mean((y_pred-y)**2)\n",
        "\n",
        "  def gradient(self):\n",
        "    return (-2/self.n)*np.matmul((self.X).T, self.y - self.forward_pass())\n",
        "\n",
        "  def update_weight(self):\n",
        "    self.weights = self.weights - self.learning_rate*self.gradient()\n",
        "\n",
        "  def call(self):\n",
        "    for i in range(self.n_iter):\n",
        "      self.update_weight()\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    m = X_test.shape[0]\n",
        "    return(np.matmul(np.array([[1.0]*m]+ list(X_test.T)).T, self.weights))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCLeezTSEVwn",
        "outputId": "1f6f252c-4de5-49bc-9aa3-f11d67d70bc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.36912549e+00],\n",
              "       [ 7.64352821e-01],\n",
              "       [-1.84018166e-03],\n",
              "       ...,\n",
              "       [ 1.57755501e+00],\n",
              "       [ 2.72010422e+00],\n",
              "       [ 1.99151057e+00]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets test the custom linear regression package i built\n",
        "\n",
        "def generate_label(X, real_weights):\n",
        "  return(np.matmul(np.array([[1.0]*(X.shape[0])]+ list(X.T)).T, real_weights))\n",
        "\n",
        "X = np.random.normal(3.0, 4.0, (10000,1))\n",
        "real_weights = [[1.0], [0.3]]\n",
        "y = generate_label(X, real_weights)\n",
        "\n",
        "# print(real_weights)\n",
        "# lin_reg = LinearRegression(X, y)\n",
        "# lin_reg.call()\n",
        "# print(lin_reg.weights)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCr9jeLbEp3i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "  return (1.0/(1.0 + np.exp(z)))\n",
        "\n",
        "\n",
        "class LogisticRegression:\n",
        "  def __init__(self, X, y):\n",
        "    self.y = y.reshape((-1,1))\n",
        "    self.n = X.shape[0]\n",
        "    self.p = X.shape[1]\n",
        "    self.X = np.array([[1.0]*(self.n)]+ list(X.T)).T\n",
        "    self.weights = np.random.normal(0,1, self.p+1).reshape((-1, 1))\n",
        "    self.learning_rate = 0.01\n",
        "    self.n_iter = 1000\n",
        "\n",
        "  def forward_pass(self):\n",
        "    return (sigmoid(-1*np.matmul(self.X, self.weights)))\n",
        "\n",
        "  def categorical_cross_entropy_loss(self):\n",
        "    y_pred = self.forward_pass()\n",
        "    log_odds = np.log(y_pred/(1-y_pred))\n",
        "    neg_pred_logs = np.log(1-y_pred)\n",
        "    return -(np.matmul((self.y).T, log_odds)[0] + np.sum(neg_pred_logs))/self.n\n",
        "\n",
        "  def gradient(self):\n",
        "    return (-1/self.n)*np.matmul((self.X).T, self.y - self.forward_pass())\n",
        "\n",
        "\n",
        "  def update_weight(self):\n",
        "    self.weights = self.weights - self.learning_rate*self.gradient()\n",
        "\n",
        "  def call(self):\n",
        "    for i in range(self.n_iter):\n",
        "      self.update_weight()\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    m = X_test.shape[0]\n",
        "    return (sigmoid(-1*np.matmul(np.array([[1.0]*m]+ list(X_test.T)).T, self.weights)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVh_HWyPJemK",
        "outputId": "ebd2b49e-497b-447d-d631-567cfad4cfdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(135, 4)\n",
            "[[8 0]\n",
            " [1 6]]\n",
            "0.9333333333333333\n",
            "[0 0 1 0 1 0 0 1 0 1 0 0 1 1 1]\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ],
      "source": [
        "# Testing my custom logistic regression package\n",
        "import sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "dataset = load_iris()\n",
        "X_data = dataset[\"data\"]\n",
        "y_data = dataset[\"target\"]\n",
        "\n",
        "def binarize_this_data(z):\n",
        "  return np.maximum(0, z-1)\n",
        "\n",
        "y_data = binarize_this_data(y_data)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.1)\n",
        "print(X_train.shape)\n",
        "classifier = LogisticRegression(X_train, y_train)\n",
        "classifier.weights\n",
        "# y_pred = classifier.forward_pass()\n",
        "classifier.call()\n",
        "# classifier.weights\n",
        "y_pred = np.maximum((classifier.predict(X_test)-0.5)/(np.abs(classifier.predict(X_test)-0.5)), 0)\n",
        "y_pred\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(y_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv3WHvTR9GrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfd38e1-f53f-4ee9-cf84-7706a54b38d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0000, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a2673db043f9>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  w = torch.tensor(w, requires_grad = True)\n"
          ]
        }
      ],
      "source": [
        "# Now we will automate stuffs using Pytorch (torch implementation of linear regression)\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
        "y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "def loss(y, y_predicted):\n",
        "  return ((y-y_predicted)**2).mean()\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epochs in range(n_iters):\n",
        "  #forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(y, y_pred)\n",
        "\n",
        "\n",
        "  # # dl/dw\n",
        "  l.backward()\n",
        "\n",
        "  # #weight update (as this should be part of computational graph for grad computation so it should be wrapped within with fn as follows)\n",
        "  with torch.no_grad():\n",
        "    w = w - learning_rate*w.grad\n",
        "\n",
        "  w = torch.tensor(w, requires_grad = True)\n",
        "  # print(w.grad)\n",
        "\n",
        "  # As we had leant that, grads keeps on accumumating on w.grad, so we need to zero them up, so zering the gradient\n",
        "\n",
        "  # w.zero_grad() # this is not applied as the gradient has already been set to none\n",
        "\n",
        "print(w)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXo4V0TwFpNJ",
        "outputId": "35d80cd3-4193-420f-de97-06a782f4028f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0000, requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Now we replace manually computed gradient and update by pytorch classes\n",
        "\n",
        "# General steps in pytroch 1) Design our model (input size, output size, forward pass ie layers and stuffs) 2) Loss and optimizer 3) training loop\n",
        "# Note, this is same as that in keras and tensorflow, which first involves model architecture fixing and the model.compile which handles loss fn,\n",
        "# optimizer, metrics etc and the model.fit carries details about training i.e data and epochs\n",
        "\n",
        "# We have fitted model in the three steps: 1) forward pass: compute predictions 2) backward pass: gradients 3) update weights\n",
        "\n",
        "# Now as we will be using the torch libraries to automate some of the stuff, one library to import is torch.nn\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
        "y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 1000\n",
        "\n",
        "loss = nn.MSELoss() # this is a callable function i.e if i input y_true and y_pred in loss it would compute the loss, will see this within the for loop\n",
        "optimizer = torch.optim.SGD([w], lr = learning_rate)\n",
        "\n",
        "for epochs in range(n_iters):\n",
        "  #forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(y, y_pred)\n",
        "\n",
        "  # # dl/dw\n",
        "  l.backward()\n",
        "\n",
        "  # #weight update (as this should be part of computational graph for grad computation so it should be wrapped within with fn as follows)\n",
        "  optimizer.step()\n",
        "\n",
        "  # # As we had leant that, grads keeps on accumumating on w.grad, so we need to zero them up, so zeroing the gradient\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(w)\n",
        "\n",
        "# This is working cool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSgYjDTvIew8",
        "outputId": "c6f2e772-75d2-465e-9c20-8e00d1fea5d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9931],\n",
              "        [5.9998]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Next here we replace every manual component i.e forward pass too, and will use pytorch fully\n",
        "\n",
        "# First thing the input and output should have proper size, i.e X is n, p and y is n,1 size matrix\n",
        "# we will not need w as the model parameters could be tracked by model.parameters() command\n",
        "# Third thing we need to input the input size and the output size as the parameter in the model\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
        "y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32)\n",
        "\n",
        "n_sample, n_feature = X.shape\n",
        "input_size = n_feature\n",
        "output_size = y.shape[1]\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 1000\n",
        "\n",
        "loss = nn.MSELoss() # this is a callable function i.e if i input y_true and y_pred in loss it would compute the loss, will see this within the for loop\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epochs in range(n_iters):\n",
        "  #forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(y, y_pred)\n",
        "\n",
        "  # # dl/dw\n",
        "  l.backward()\n",
        "\n",
        "  # #weight update (as this should be part of computational graph for grad computation so it should be wrapped within with fn as follows)\n",
        "  optimizer.step()\n",
        "\n",
        "  # # As we had leant that, grads keeps on accumumating on w.grad, so we need to zero them up, so zering the gradient\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "model(torch.tensor([[5.0], [3.0]]))\n",
        "\n",
        "# This is working cool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhxkQK1PJNg-",
        "outputId": "a0e45a17-1116-45c6-8dc8-9213391ba6ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[9.9779],\n",
              "        [5.9994]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# custom linear model using subclassing technique\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
        "y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32)\n",
        "\n",
        "n_sample, n_feature = X.shape\n",
        "input_size = n_feature\n",
        "output_size = y.shape[1]\n",
        "\n",
        "\n",
        "# Model using subclassing technique\n",
        "\n",
        "class LinearReg(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_size, output_size)\n",
        "\n",
        "  # also need to implement the forward pass\n",
        "  def forward(self, X):\n",
        "    return self.lin(X)\n",
        "\n",
        "model = LinearReg(input_size, output_size)\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 1000\n",
        "\n",
        "loss = nn.MSELoss() # this is a callable function i.e if i input y_true and y_pred in loss it would compute the loss, will see this within the for loop\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epochs in range(n_iters):\n",
        "  #forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(y, y_pred)\n",
        "\n",
        "  # # dl/dw\n",
        "  l.backward()\n",
        "\n",
        "  # #weight update (as this should be part of computational graph for grad computation so it should be wrapped within with fn as follows)\n",
        "  optimizer.step()\n",
        "\n",
        "  # # As we had leant that, grads keeps on accumumating on w.grad, so we need to zero them up, so zering the gradient\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "model(torch.tensor([[5.0], [3.0]]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap70VsyRhQYK",
        "outputId": "d0435ce7-6306-4560-a200-c689ae397af8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.3478],\n",
              "        [1.7887],\n",
              "        [2.2297],\n",
              "        [2.6706]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LinearReg(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_size, output_size)\n",
        "\n",
        "  # also need to implement the forward pass\n",
        "  def forward(self, X):\n",
        "    return self.lin(X)\n",
        "\n",
        "model = LinearReg(input_size, output_size)\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
        "\n",
        "Model = LinearReg(input_size, output_size)\n",
        "Model(X)\n",
        "\n",
        "# Here we do not need to get the values by Model.forward(X) and just Model(X) is enough, this is\n",
        "# In the super class, nn.Module, there is a __call__ method which obtains the forward function\n",
        "# from the subclass and calls it., to read more about all this refer to the following link:\n",
        "# https://medium.com/@ariellemesser/pytorch-nn-module-super-classes-sub-classes-inheritance-and-call-speci-3cc277407ff5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now i will fit logistic regression using pytorch, where the model will be built using subclassing API\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# There are four steps in fitting the model, 1) preparing dataset 2) fitting model architecture\n",
        "# 3) loss and optimizer 4) Training (forward pass(compute prediction and loss),\n",
        "# backward pass (compute gradient) and update weight)\n",
        "\n",
        "# Lets being\n",
        "\n",
        "# 0) Dataset\n",
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "X_data = bc[\"data\"]\n",
        "y_data = bc[\"target\"]\n",
        "\n",
        "y_data = y_data.reshape((-1, 1))\n",
        "y_data.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.1)\n",
        "\n",
        "#scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Converting to torch array from numpy\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "# 1) Model (will build using subclassing api)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "n_instance, n_features = X_train.shape\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_shape):\n",
        "    super().__init__()\n",
        "    self.lin_layer = nn.Linear(input_shape, 1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return torch.sigmoid(self.lin_layer(X))\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for i in range(n_iters):\n",
        "\n",
        "  # forward_pass (prediction + loss)\n",
        "  y_pred = model(X_train)\n",
        "\n",
        "  l = loss(y_pred, y_train)\n",
        "\n",
        "  # compute gradient\n",
        "\n",
        "  l.backward()\n",
        "\n",
        "  # update_weights + empty_grad\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "test_pred = model(X_test)\n",
        "\n",
        "# Finding predictions and converting it into numpy for accuracy score to work, this also needs detach to detach it from gard stuff\n",
        "y_predictions = test_pred.round().detach().numpy()\n",
        "\n",
        "print(accuracy_score(y_predictions, y_test.numpy()))\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxSJ75goVYan",
        "outputId": "cc6a0f2e-be23-42df-de74-84b71776c731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9298245614035088\n",
            "0.05435967445373535\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpy4gGtomEMb",
        "outputId": "751f8b9c-fc43-479c-b7d2-e5003bd55a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9824561403508771\n",
            "0.0670475959777832\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Now i will fit logistic regression using pytorch, where the model will be built using subclassing API\n",
        "# (trying the same stuff on GPU)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# There are four steps in fitting the model, 1) preparing dataset 2) fitting model architecture\n",
        "# 3) loss and optimizer 4) Training (forward pass(compute prediction and loss),\n",
        "# backward pass (compute gradient) and update weight)\n",
        "\n",
        "# Lets being\n",
        "\n",
        "# 0) Dataset\n",
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "X_data = bc[\"data\"]\n",
        "y_data = bc[\"target\"]\n",
        "\n",
        "y_data = y_data.reshape((-1, 1))\n",
        "y_data.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.1)\n",
        "\n",
        "#scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Converting to torch array from numpy\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32)).to(device)\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32)).to(device)\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32)).to(device)\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32)).to(device)\n",
        "\n",
        "# 1) Model (will build using subclassing api)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "n_instance, n_features = X_train.shape\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_shape):\n",
        "    super().__init__()\n",
        "    self.lin_layer = nn.Linear(input_shape, 1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return torch.sigmoid(self.lin_layer(X))\n",
        "\n",
        "model = LogisticRegression(n_features).to(device)\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for i in range(n_iters):\n",
        "\n",
        "  # forward_pass (prediction + loss)\n",
        "  y_pred = model(X_train)\n",
        "\n",
        "  l = loss(y_pred, y_train)\n",
        "\n",
        "  # compute gradient\n",
        "\n",
        "  l.backward()\n",
        "\n",
        "  # update_weights + empty_grad\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "test_pred = model(X_test)\n",
        "\n",
        "# Finding predictions and converting it into numpy for accuracy score to work, this also needs detach to detach it from gard stuff\n",
        "y_predictions = test_pred.round().detach().cpu().numpy()\n",
        "\n",
        "print(accuracy_score(y_predictions, y_test.cpu().numpy()))\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNiRBxUs6ilO"
      },
      "outputs": [],
      "source": [
        "# Now dataset and Dataloader in pytorch\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Will do later\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4o6AYhKFtZ7"
      },
      "outputs": [],
      "source": [
        "# Dataset Transform\n",
        "\n",
        "# torch.softmax, nn.CrossEntropyLoss()\n",
        "# Gyan: For nn.BCELoss(), torch.sigmoid needs to be computed before but torch.softmax doesn't need to be computed for nn.CrossEntropyLoss()\n",
        "\n",
        "# Command Dictionary\n",
        "# import torch.nn as nn\n",
        "# torch.nn\n",
        "# nn.Module\n",
        "# torch.sigmoid\n",
        "# torch.softmax\n",
        "# torch.relu\n",
        "# torch.tanh\n",
        "# nn.MSELoss()\n",
        "# nn.BCELoss()\n",
        "# nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()\n",
        "# nn.Linear(input_size, output_size)\n",
        "# nn.ReLU\n",
        "# nn.TanH\n",
        "# nn.Sigmoid\n",
        "# nn.Softmax\n",
        "# nn.LeakyReLU\n",
        "# import torch.nn.Functional as F\n",
        "# F.relu()\n",
        "# F.leaky_relu()\n",
        "\n",
        "\n",
        "# layer\n",
        "nn.Linear\n",
        "\n",
        "# activation\n",
        "nn.ReLU\n",
        "nn.Sigmoid\n",
        "nn.TanH\n",
        "nn.Softmax\n",
        "nn.LeakyReLU\n",
        "import torch.nn.Functional as F\n",
        "F.relu()\n",
        "F.leaky_relu()\n",
        "\n",
        "# loss\n",
        "nn.MSELoss()\n",
        "nn.BCELoss()\n",
        "nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# subclassing is done on nn.Module and within it the initialization has to be done and the forward method has to be written, for example\n",
        "\n",
        "class MyNeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.linear_layer = nn.Linear(input_size, hidden_size)\n",
        "    self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
        "    self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.linear_layer(X)\n",
        "    X = nn.ReLU(X)\n",
        "    X = self.hidden_layer(X)\n",
        "    X = nn.Functional.leaky_relu(X)\n",
        "    X = self.output_layer(X)\n",
        "    return nn.Sigmoid(X)\n",
        "\n",
        "model = MyNeuralNetwork(input_size = 10, output_size = 1, hidden_size = 5)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XccQSvxHVVVz"
      },
      "outputs": [],
      "source": [
        "# Now, lets build an algorithm for binary classification problem using pytorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Binary Classification\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    out = self.linear1(X)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    # sigmoid at the end\n",
        "    y_pred = torch.sigmoid(out)\n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvrpfyi6ao6S"
      },
      "outputs": [],
      "source": [
        "model = NeuralNet(input_size = 28*28, hidden_size = 5)\n",
        "criteria = nn.BCELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTg-BQ10a1i2"
      },
      "outputs": [],
      "source": [
        "# Dataset and Dataloader\n",
        "\n",
        "# First i will load wine data set from sklearn.datasets to work on it\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "import numpy as np\n",
        "\n",
        "wine_data = load_wine()\n",
        "\n",
        "X_data = wine_data[\"data\"]\n",
        "y_data = wine_data[\"target\"]\n",
        "data = np.concatenate((X_data, y_data.reshape(-1, 1)), axis = 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAlexeIpMQx6",
        "outputId": "b73b4692-8f2a-4005-b3cb-977c29b48663"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.4230e+01, 1.7100e+00, 2.4300e+00,  ..., 1.0400e+00, 3.9200e+00,\n",
              "         1.0650e+03],\n",
              "        [1.3200e+01, 1.7800e+00, 2.1400e+00,  ..., 1.0500e+00, 3.4000e+00,\n",
              "         1.0500e+03],\n",
              "        [1.3160e+01, 2.3600e+00, 2.6700e+00,  ..., 1.0300e+00, 3.1700e+00,\n",
              "         1.1850e+03],\n",
              "        ...,\n",
              "        [1.3270e+01, 4.2800e+00, 2.2600e+00,  ..., 5.9000e-01, 1.5600e+00,\n",
              "         8.3500e+02],\n",
              "        [1.3170e+01, 2.5900e+00, 2.3700e+00,  ..., 6.0000e-01, 1.6200e+00,\n",
              "         8.4000e+02],\n",
              "        [1.4130e+01, 4.1000e+00, 2.7400e+00,  ..., 6.1000e-01, 1.6000e+00,\n",
              "         5.6000e+02]], dtype=torch.float64)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now we will learn the classes Dataset and Dataloader\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineData(Dataset):\n",
        "  def __init__(self):  # this is used for dataloading\n",
        "    self.xy = data # defined in the last code block\n",
        "    self.x = torch.from_numpy(self.xy[:, :-1])\n",
        "    self.y = torch.from_numpy(self.xy[:, [-1]])\n",
        "    self.n_sample = (self.xy).shape[0]\n",
        "\n",
        "  def __getitem__(self, index): # this is magical method for indexing, if i use data[i] it will return self.__getitem__(i)\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self): # this is magical method form finding length, so if i use len(data) it will compute the lenth\n",
        "    return self.n_sample\n",
        "\n",
        "# Now lets create the dataset\n",
        "\n",
        "dataset = WineData()\n",
        "# first_data = dataset[0]\n",
        "# features, label = first_data\n",
        "# print(features)\n",
        "# print(label)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUxgmeSeNA0t",
        "outputId": "afd1d447-fc91-4169-def5-e7ed13e76c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "tensor([[1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "         1.0650e+03],\n",
            "        [1.3580e+01, 1.6600e+00, 2.3600e+00, 1.9100e+01, 1.0600e+02, 2.8600e+00,\n",
            "         3.1900e+00, 2.2000e-01, 1.9500e+00, 6.9000e+00, 1.0900e+00, 2.8800e+00,\n",
            "         1.5150e+03],\n",
            "        [1.2420e+01, 1.6100e+00, 2.1900e+00, 2.2500e+01, 1.0800e+02, 2.0000e+00,\n",
            "         2.0900e+00, 3.4000e-01, 1.6100e+00, 2.0600e+00, 1.0600e+00, 2.9600e+00,\n",
            "         3.4500e+02],\n",
            "        [1.4340e+01, 1.6800e+00, 2.7000e+00, 2.5000e+01, 9.8000e+01, 2.8000e+00,\n",
            "         1.3100e+00, 5.3000e-01, 2.7000e+00, 1.3000e+01, 5.7000e-01, 1.9600e+00,\n",
            "         6.6000e+02]], dtype=torch.float64) tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [2.]], dtype=torch.float64)\n",
            "1\n",
            "tensor([[1.2170e+01, 1.4500e+00, 2.5300e+00, 1.9000e+01, 1.0400e+02, 1.8900e+00,\n",
            "         1.7500e+00, 4.5000e-01, 1.0300e+00, 2.9500e+00, 1.4500e+00, 2.2300e+00,\n",
            "         3.5500e+02],\n",
            "        [1.2220e+01, 1.2900e+00, 1.9400e+00, 1.9000e+01, 9.2000e+01, 2.3600e+00,\n",
            "         2.0400e+00, 3.9000e-01, 2.0800e+00, 2.7000e+00, 8.6000e-01, 3.0200e+00,\n",
            "         3.1200e+02],\n",
            "        [1.3630e+01, 1.8100e+00, 2.7000e+00, 1.7200e+01, 1.1200e+02, 2.8500e+00,\n",
            "         2.9100e+00, 3.0000e-01, 1.4600e+00, 7.3000e+00, 1.2800e+00, 2.8800e+00,\n",
            "         1.3100e+03],\n",
            "        [1.2340e+01, 2.4500e+00, 2.4600e+00, 2.1000e+01, 9.8000e+01, 2.5600e+00,\n",
            "         2.1100e+00, 3.4000e-01, 1.3100e+00, 2.8000e+00, 8.0000e-01, 3.3800e+00,\n",
            "         4.3800e+02]], dtype=torch.float64) tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]], dtype=torch.float64)\n",
            "2\n",
            "tensor([[1.2510e+01, 1.2400e+00, 2.2500e+00, 1.7500e+01, 8.5000e+01, 2.0000e+00,\n",
            "         5.8000e-01, 6.0000e-01, 1.2500e+00, 5.4500e+00, 7.5000e-01, 1.5100e+00,\n",
            "         6.5000e+02],\n",
            "        [1.3050e+01, 2.0500e+00, 3.2200e+00, 2.5000e+01, 1.2400e+02, 2.6300e+00,\n",
            "         2.6800e+00, 4.7000e-01, 1.9200e+00, 3.5800e+00, 1.1300e+00, 3.2000e+00,\n",
            "         8.3000e+02],\n",
            "        [1.3880e+01, 1.8900e+00, 2.5900e+00, 1.5000e+01, 1.0100e+02, 3.2500e+00,\n",
            "         3.5600e+00, 1.7000e-01, 1.7000e+00, 5.4300e+00, 8.8000e-01, 3.5600e+00,\n",
            "         1.0950e+03],\n",
            "        [1.3860e+01, 1.5100e+00, 2.6700e+00, 2.5000e+01, 8.6000e+01, 2.9500e+00,\n",
            "         2.8600e+00, 2.1000e-01, 1.8700e+00, 3.3800e+00, 1.3600e+00, 3.1600e+00,\n",
            "         4.1000e+02]], dtype=torch.float64) tensor([[2.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.]], dtype=torch.float64)\n",
            "3\n",
            "tensor([[1.2250e+01, 1.7300e+00, 2.1200e+00, 1.9000e+01, 8.0000e+01, 1.6500e+00,\n",
            "         2.0300e+00, 3.7000e-01, 1.6300e+00, 3.4000e+00, 1.0000e+00, 3.1700e+00,\n",
            "         5.1000e+02],\n",
            "        [1.3670e+01, 1.2500e+00, 1.9200e+00, 1.8000e+01, 9.4000e+01, 2.1000e+00,\n",
            "         1.7900e+00, 3.2000e-01, 7.3000e-01, 3.8000e+00, 1.2300e+00, 2.4600e+00,\n",
            "         6.3000e+02],\n",
            "        [1.2290e+01, 1.6100e+00, 2.2100e+00, 2.0400e+01, 1.0300e+02, 1.1000e+00,\n",
            "         1.0200e+00, 3.7000e-01, 1.4600e+00, 3.0500e+00, 9.0600e-01, 1.8200e+00,\n",
            "         8.7000e+02],\n",
            "        [1.3050e+01, 1.7300e+00, 2.0400e+00, 1.2400e+01, 9.2000e+01, 2.7200e+00,\n",
            "         3.2700e+00, 1.7000e-01, 2.9100e+00, 7.2000e+00, 1.1200e+00, 2.9100e+00,\n",
            "         1.1500e+03]], dtype=torch.float64) tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]], dtype=torch.float64)\n",
            "4\n",
            "tensor([[1.4300e+01, 1.9200e+00, 2.7200e+00, 2.0000e+01, 1.2000e+02, 2.8000e+00,\n",
            "         3.1400e+00, 3.3000e-01, 1.9700e+00, 6.2000e+00, 1.0700e+00, 2.6500e+00,\n",
            "         1.2800e+03],\n",
            "        [1.1840e+01, 2.8900e+00, 2.2300e+00, 1.8000e+01, 1.1200e+02, 1.7200e+00,\n",
            "         1.3200e+00, 4.3000e-01, 9.5000e-01, 2.6500e+00, 9.6000e-01, 2.5200e+00,\n",
            "         5.0000e+02],\n",
            "        [1.1030e+01, 1.5100e+00, 2.2000e+00, 2.1500e+01, 8.5000e+01, 2.4600e+00,\n",
            "         2.1700e+00, 5.2000e-01, 2.0100e+00, 1.9000e+00, 1.7100e+00, 2.8700e+00,\n",
            "         4.0700e+02],\n",
            "        [1.1640e+01, 2.0600e+00, 2.4600e+00, 2.1600e+01, 8.4000e+01, 1.9500e+00,\n",
            "         1.6900e+00, 4.8000e-01, 1.3500e+00, 2.8000e+00, 1.0000e+00, 2.7500e+00,\n",
            "         6.8000e+02]], dtype=torch.float64) tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], dtype=torch.float64)\n",
            "5\n",
            "tensor([[1.1820e+01, 1.4700e+00, 1.9900e+00, 2.0800e+01, 8.6000e+01, 1.9800e+00,\n",
            "         1.6000e+00, 3.0000e-01, 1.5300e+00, 1.9500e+00, 9.5000e-01, 3.3300e+00,\n",
            "         4.9500e+02],\n",
            "        [1.4100e+01, 2.1600e+00, 2.3000e+00, 1.8000e+01, 1.0500e+02, 2.9500e+00,\n",
            "         3.3200e+00, 2.2000e-01, 2.3800e+00, 5.7500e+00, 1.2500e+00, 3.1700e+00,\n",
            "         1.5100e+03],\n",
            "        [1.3300e+01, 1.7200e+00, 2.1400e+00, 1.7000e+01, 9.4000e+01, 2.4000e+00,\n",
            "         2.1900e+00, 2.7000e-01, 1.3500e+00, 3.9500e+00, 1.0200e+00, 2.7700e+00,\n",
            "         1.2850e+03],\n",
            "        [1.3840e+01, 4.1200e+00, 2.3800e+00, 1.9500e+01, 8.9000e+01, 1.8000e+00,\n",
            "         8.3000e-01, 4.8000e-01, 1.5600e+00, 9.0100e+00, 5.7000e-01, 1.6400e+00,\n",
            "         4.8000e+02]], dtype=torch.float64) tensor([[1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [2.]], dtype=torch.float64)\n",
            "6\n",
            "tensor([[1.1760e+01, 2.6800e+00, 2.9200e+00, 2.0000e+01, 1.0300e+02, 1.7500e+00,\n",
            "         2.0300e+00, 6.0000e-01, 1.0500e+00, 3.8000e+00, 1.2300e+00, 2.5000e+00,\n",
            "         6.0700e+02],\n",
            "        [1.3490e+01, 1.6600e+00, 2.2400e+00, 2.4000e+01, 8.7000e+01, 1.8800e+00,\n",
            "         1.8400e+00, 2.7000e-01, 1.0300e+00, 3.7400e+00, 9.8000e-01, 2.7800e+00,\n",
            "         4.7200e+02],\n",
            "        [1.3870e+01, 1.9000e+00, 2.8000e+00, 1.9400e+01, 1.0700e+02, 2.9500e+00,\n",
            "         2.9700e+00, 3.7000e-01, 1.7600e+00, 4.5000e+00, 1.2500e+00, 3.4000e+00,\n",
            "         9.1500e+02],\n",
            "        [1.3860e+01, 1.3500e+00, 2.2700e+00, 1.6000e+01, 9.8000e+01, 2.9800e+00,\n",
            "         3.1500e+00, 2.2000e-01, 1.8500e+00, 7.2200e+00, 1.0100e+00, 3.5500e+00,\n",
            "         1.0450e+03]], dtype=torch.float64) tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Now lets use Dataloader\n",
        "\n",
        "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 2)\n",
        "enumerate(dataloader)\n",
        "for i, (x, y) in enumerate(dataloader):\n",
        "  if i> 6:\n",
        "    break\n",
        "  print (i)\n",
        "  print (x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS0n47_pTWyw",
        "outputId": "2f71a110-3744-4fb4-ddd0-8066f5bed492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178 45\n"
          ]
        }
      ],
      "source": [
        "# Dummy training loop\n",
        "\n",
        "num_epochs = 2\n",
        "total_sample = len(dataset)\n",
        "\n",
        "n_iteration = math.ceil(total_sample/4) # as 4 is the batch size we are using\n",
        "\n",
        "print(total_sample, n_iteration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQTDDtEAr_KD",
        "outputId": "3a930e03-fc56-489a-bd25-b6461f9a7a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 1/2, step: 5/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 10/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 15/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 20/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 25/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 30/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 35/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 40/45, inputs: torch.Size([4, 13])\n",
            "epochs: 1/2, step: 45/45, inputs: torch.Size([2, 13])\n",
            "epochs: 2/2, step: 5/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 10/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 15/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 20/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 25/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 30/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 35/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 40/45, inputs: torch.Size([4, 13])\n",
            "epochs: 2/2, step: 45/45, inputs: torch.Size([2, 13])\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (input, labels) in enumerate(dataloader):\n",
        "    # forward\n",
        "\n",
        "    # backward\n",
        "\n",
        "    # update_weights\n",
        "\n",
        "    if (i+1)%5==0:\n",
        "      print(f\"epochs: {epoch+1}/{num_epochs}, step: {i+1}/{n_iteration}, inputs: {input.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522,
          "referenced_widgets": [
            "c995f27392c3485d8550ca2045c78d62",
            "ce3756211b854104835290723be6c350",
            "bd9049cce1f343daaafc93e5bc7b079b",
            "22eba0a108f24b819bfd87d589db3d7c",
            "dffbc6110aec4251a53904136e27ef60",
            "79978348aebb46df88dfe8e1cfbef674",
            "9aa88a0acca94bb1b295ddf49f0a839d",
            "144f2899607d4fddb5efca2cb174bffd",
            "48aa3e6d68e044799c7249dd3231785d",
            "3c8eca5e10bd4dab95fefde7f7276425",
            "136cdb0e10b34861941d4e3667d5b641",
            "d1370fbe1ae64a77a9bb8c9985a3e83d",
            "319ecc66592640649af2f5b59dd92761",
            "cf6149624f24416d893b3022dc130851",
            "0b2803911da3449d9a95de19ee7f87c8",
            "ea1b906035774ed08eb378bd5fca9369",
            "4676af5b099f4b34815eeaaf2ca9e71b",
            "d7d2064699754cfc92b3124ebb2ac93b",
            "42f4224654ad410e8b3d79b58600fa6d",
            "ed8475f02b6e4ad1b2cefaa563696101",
            "a8348aa10ad7419c9bfa48753a190f90",
            "9f29cc9a800c417eb8fbd4c3eb3b6bdd",
            "ca74914a2736480882ddf592e4b9192c",
            "d9c2670566b0426788f855a9e2b3cff0",
            "bf43cefd0a3343f4aa067a9b90fb52b3",
            "72545c70592143788aac27ad4e4e9d4a",
            "43ebda24206049689efaf113b6e31f77",
            "886c448eaf3045d2b623f84011b347e5",
            "3a850ff3f58246409301b8f6c3677100",
            "b197087c66684680a7e45738bba4bd2b",
            "e56cfa3c98334b7b82c84fb5c4e6a4d9",
            "5961e3fa6ae949d6982311db66b59f72",
            "40629ce99dfa455986979ad879677692",
            "5705c5c2fc914352a4017fdfa76d479e",
            "45e265a7fe894ee88eb10fe2a9869c32",
            "4d197e4c2f8d424e9403ca5d74c987dd",
            "302642b0ab304e9aad070b8fd9452b7b",
            "2b49c8be38e249789d58b5a276361ac8",
            "900ba6712f1a4ad78048b8bd47215c2a",
            "b6df793da958409b8c3ffcedec69f9b5",
            "6f8acc2d78884c09b2ed4b9835f4703e",
            "a3276b4721ca4bfba5e89e9bc6827775",
            "a47e305cce0344fcaa8607f5c0624a22",
            "b7f27fdcf26b4438b2c745444717f7e7"
          ]
        },
        "id": "CEBpwd-XuCyR",
        "outputId": "71df7cb5-690d-4369-ca3d-16012724c8ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c995f27392c3485d8550ca2045c78d62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/train-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1370fbe1ae64a77a9bb8c9985a3e83d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca74914a2736480882ddf592e4b9192c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5705c5c2fc914352a4017fdfa76d479e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /content/sample_data\n",
              "    Split: Train"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Also pytoch has its own datasets as well for example MNSIT dataset\n",
        "# could be loaded using the commnad torchvision.datasets.MNIST(), lets try to run it now\n",
        "\n",
        "torchvision.datasets.MNIST(root = \"/content/sample_data\", download = True) # root here is the location where i want to dowsnload the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451,
          "referenced_widgets": [
            "c4155f6d259740f4aaee49058bc823fa",
            "0a2e0b776f9c49cba579ad2db981ec25",
            "1d54a42d004a4710a5a9b8db21e7d0bb",
            "15999ab899604af49bb053b436da5cef",
            "25cd9bc675694cc1a34a881117fc180c",
            "01d87807901045ccb7aa3f5e2a8cb603",
            "034767d9709f46689dda41bd5fc289bb",
            "6efde7b29bc84cdf8d827c97c4f51e22",
            "8e79b874c2b1471185e8b34f136bc9aa",
            "9ea4ea8c1bc648738931d614c2884119",
            "8cf6ed6ecd9f4560b97b1bbbfbd7cac0",
            "ba0151714ba74bc98be98935296bd713",
            "424de6e444744e6cace3383f0cee6d4f",
            "7665f37d9a2d4cd5b96879bef80264f0",
            "8b63ab425f0844a794f9b529c745c4fa",
            "04c78579ecec4e3288ecee96d06ec600",
            "81e04fcbb49f4d6a98331fe48f7dc38b",
            "fc85af554f774c609ea29f08b2437fe2",
            "29824d2c2be44ffaaf84f20d7cb21bdf",
            "6faadc1431a346e787a9aa6730e95ac7",
            "69fc15405fa14df89635a063640cd6fb",
            "0354a44111b145b28ac3bf5a42cbb572",
            "5199d9fbfb3f4aa68dd0ad1db492c1d9",
            "9dac878b082f4e0cbf160169194ae073",
            "8ebcf3f1b72a4e9cb7d88606aba293a9",
            "069cf16fbe814f8c96d033a0c99ce4f5",
            "0a54912a9edb4b94a0e590e0574cd6e3",
            "4dbdacce56b04a75a64347ba1eaec984",
            "18804b8466704ac78f2d1ddf9edea1e4",
            "7a36369482144a729bb86728371dfe71",
            "b9d340b251c04e5389c4f66abffdc612",
            "f8c4e19360624925a7a17f25e00c28cd",
            "8783d9d51f87488482829d17180de862",
            "09a064fdf7f8412c83897b5ce50cf480",
            "e47e6b12c45641ac8c00878f7d9d69c8",
            "86bb5752af754399bde85094a27bf6ba",
            "496ffd7d59b14b00b1d08e7cbff8de5e",
            "9eb107a8c452458c9765be1c5e3e0ecb",
            "57301404796e48d6a69a62fd82d1af15",
            "8536e5b9acdf4a9fbeae87e603ff2a0b",
            "986254d4384544e79435c73c0d379965",
            "169e1f901cc4446589e65d3e18df5c58",
            "fd11904b9d3e4580a1ef69b00f78c56b",
            "ae2c070110d04a70871e640b1a418990"
          ]
        },
        "id": "cgo2ibEnvJIs",
        "outputId": "f9ca7cea-3f3b-4bed-9519-424983475ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4155f6d259740f4aaee49058bc823fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/train-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba0151714ba74bc98be98935296bd713",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5199d9fbfb3f4aa68dd0ad1db492c1d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09a064fdf7f8412c83897b5ce50cf480",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/sample_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/sample_data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Dataset Transform\n",
        "\n",
        "# What transform does is tranforming the images, for example convert the numpy array to torch tensors\n",
        "# and a lot others tranformation is supported evcen custom transforms can be made\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "dataset = torchvision.datasets.MNIST(root = \"/content/sample_data\", transform = torchvision.transforms.ToTensor(), download = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg2n39VMs2AQ",
        "outputId": "6826e54d-e8fa-4705-86db-5378311dc1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03], dtype=torch.float64)\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "# Last we built wine dataset class not lets equip it with custom transformation\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# First i will load wine data set from sklearn.datasets to work on it\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "import numpy as np\n",
        "\n",
        "wine_data = load_wine()\n",
        "\n",
        "X_data = wine_data[\"data\"]\n",
        "y_data = wine_data[\"target\"]\n",
        "data = np.concatenate((X_data, y_data.reshape(-1, 1)), axis = 1)\n",
        "\n",
        "# Now our dataset class will contain tranform too, lets look at the code below\n",
        "\n",
        "class WineData(Dataset):\n",
        "  def __init__(self, transform = None):  # this is used for dataloading\n",
        "    self.xy = data # defined in the last code block\n",
        "    self.x = self.xy[:, :-1]\n",
        "    self.y = self.xy[:, [-1]]\n",
        "    self.transform = transform\n",
        "    self.n_sample= (self.xy).shape[0]\n",
        "\n",
        "  def __getitem__(self, index): # this is magical method for indexing, if i use data[i] it will return self.__getitem__(i)\n",
        "    sample =  self.x[index], self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      return self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self): # this is magical method form finding length, so if i use len(data) it will compute the lenth\n",
        "    return self.n_sample\n",
        "\n",
        "# Lets create a custom ToTensor class\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "# lets create another tranform\n",
        "\n",
        "class MulTransform():\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    inputs, label = sample\n",
        "    return self.factor*inputs, labels\n",
        "\n",
        "# Now lets create the dataset\n",
        "\n",
        "dataset = WineData(transform = ToTensor())\n",
        "\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "\n",
        "print(features)\n",
        "print(type(features))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytwsy_GEy7ij"
      },
      "outputs": [],
      "source": [
        "# now lets learn composed tranforms\n",
        "\n",
        "composed = torchvision.tranforms.Compose([ToTensor(), MulTransform(2.0)])\n",
        "\n",
        "dataset = WineData(transform = composed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZESd3BYb8UEV"
      },
      "outputs": [],
      "source": [
        "# Now lets build a multiclass neural network, note nn.CrossEntropyLoss() doesn't\n",
        "# work on the softmax values rather it works on the values on which softmax is applied\n",
        "import torch.nn as nn\n",
        "class NeuralNetwork2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_classes = num_classes\n",
        "    self.linear1 = nn.Linear(self.input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.output = nn.Linear(self.hidden_size, self.num_classes)\n",
        "\n",
        "  def forward(self, X):\n",
        "    Z = self.linear1(X)\n",
        "    Z = self.relu(Z)\n",
        "    Z = self.linear2(Z)\n",
        "    Z = self.relu(Z)\n",
        "    Z = self.output(Z)\n",
        "    # no softmax at the end\n",
        "    return Z\n",
        "\n",
        "model = NeuralNetwork2(input_size= 28*28, hidden_size = 50, num_classes = 3)\n",
        "criterian = nn.CrossEntropyLoss() # This applies softmax on the output and then computes the loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ifNPhwO-6Jj"
      },
      "outputs": [],
      "source": [
        "# Feedforward Neural Network\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# devise config\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# hyperparameter\n",
        "\n",
        "input_size = 784 #28*28\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "# MNIST\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root = \"/content/sample_data\", train = True, transform = transforms.ToTensor(), download = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root = \"/content/sample_data\", train = False, transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "C6-NxsPkIZKi",
        "outputId": "99b93bb0-1992-439e-ea21-ac80d990fc49"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "examples = iter(train_loader)\n",
        "plt.imshow(list(examples)[0][0][0][0], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "RkoOk5EgIxfl",
        "outputId": "60662b04-b9ec-46ac-9683-68d7a3110cb5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "examples = iter(train_loader)\n",
        "samples = list(examples)\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(samples[0][0][50+i][0], cmap = \"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kRfaYwTMOv-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_classes = num_classes\n",
        "    self.linear1 = nn.Linear(self.input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.output = nn.Linear(self.hidden_size, self.num_classes)\n",
        "\n",
        "  def forward(self, X):\n",
        "    Z = self.linear1(X)\n",
        "    Z = self.relu(Z)\n",
        "    Z = self.linear2(Z)\n",
        "    Z = self.relu(Z)\n",
        "    Z = self.output(Z)\n",
        "    # no softmax at the end\n",
        "    return Z\n",
        "\n",
        "model = NeuralNetwork(10, 8, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M799_yi5MW4u",
        "outputId": "37054dbf-7186-4c76-9448-f2da9c621838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch: 1/4, Step: 2000/12500, Loss: 1.3391 \n",
            "Epoch: 1/4, Step: 4000/12500, Loss: 1.7756 \n",
            "Epoch: 1/4, Step: 6000/12500, Loss: 2.3612 \n",
            "Epoch: 1/4, Step: 8000/12500, Loss: 1.6340 \n",
            "Epoch: 1/4, Step: 10000/12500, Loss: 1.3921 \n",
            "Epoch: 1/4, Step: 12000/12500, Loss: 1.4833 \n",
            "Epoch: 2/4, Step: 2000/12500, Loss: 1.5564 \n",
            "Epoch: 2/4, Step: 4000/12500, Loss: 1.9368 \n",
            "Epoch: 2/4, Step: 6000/12500, Loss: 1.0725 \n",
            "Epoch: 2/4, Step: 8000/12500, Loss: 1.0650 \n",
            "Epoch: 2/4, Step: 10000/12500, Loss: 1.5954 \n",
            "Epoch: 2/4, Step: 12000/12500, Loss: 1.8940 \n",
            "Epoch: 3/4, Step: 2000/12500, Loss: 0.5032 \n",
            "Epoch: 3/4, Step: 4000/12500, Loss: 0.6377 \n",
            "Epoch: 3/4, Step: 6000/12500, Loss: 1.3550 \n",
            "Epoch: 3/4, Step: 8000/12500, Loss: 3.1926 \n",
            "Epoch: 3/4, Step: 10000/12500, Loss: 1.7516 \n",
            "Epoch: 3/4, Step: 12000/12500, Loss: 0.7931 \n",
            "Epoch: 4/4, Step: 2000/12500, Loss: 0.2616 \n",
            "Epoch: 4/4, Step: 4000/12500, Loss: 0.6615 \n",
            "Epoch: 4/4, Step: 6000/12500, Loss: 2.5223 \n",
            "Epoch: 4/4, Step: 8000/12500, Loss: 0.4311 \n",
            "Epoch: 4/4, Step: 10000/12500, Loss: 1.7379 \n",
            "Epoch: 4/4, Step: 12000/12500, Loss: 0.9023 \n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Convolution Neural Network\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Devise configuration\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.01\n",
        "\n",
        "# dataset has PILImage of range [0,1], we transform them to torch tensors and normalize it to in the range [-1,1]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = \"/content/sample_data\", download = True, transform = transform, train=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = \"/content/sample_data\", download = True, transform = transform, train=False)\n",
        "\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "classes = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Implement ConvNet\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5) # here 3 is the number of channels in the input, now as it is image with 3 channels so three, 6 is number of filters and 5 is kernel size\n",
        "    self.pool = nn.MaxPool2d(2, 2) # the first 2 is the kernel size and the second 2 is the stride\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.pool(F.relu(self.conv1(X)))\n",
        "    X = self.pool(F.relu(self.conv2(X)))\n",
        "    X = X.view((-1, 16*5*5))\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # original shape = [batch_size = 4, channels =3, height = 32, width = 32]\n",
        "    # input_layer: 3 input channels, 6 output channels and 5 kernel size\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backprop and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%2000 ==0:\n",
        "      print(f\"Epoch: {epoch+1}/{num_epochs}, Step: {i+1}/{n_total_steps}, Loss: {loss.item():.4f} \")\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Evaluation of the trained model\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   n_correct = 0\n",
        "#   n_samples = 0\n",
        "#   n_class_correct = [0 for i in range(10)]\n",
        "#   n_class_samples = [0 for i in range(10)]\n",
        "#   for images, labels in test_loader:\n",
        "#     images = images.to(device)\n",
        "#     labels = labels.to(device)\n",
        "#     outputs = model(images)\n",
        "#     # max, return (value, index)\n",
        "#     _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Need to complete it to find accuracy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb_BOW-ttfzn",
        "outputId": "a1c50d97-eff6-412f-e676-6e9a477ee25b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.max(torch.tensor([[0.1, 0.2, 0.0, 0.4, 0.0, 0.01, 0.09, 0.1, 0.05, 0.05]]), torch.tensor([[1]*10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzn7stLehovH"
      },
      "outputs": [],
      "source": [
        "# Tranfer Learning\n",
        "\n",
        "# three new thing we would see here\n",
        "# ImageFolder, Learning Rate Scheduler, Transfer Learning\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import tranforms, models, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\"train\":transforms.Compose([transforms.RandomResizedCrop(224), ])}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hax61mTM7S0E",
        "outputId": "aa08c3d0-13fb-49f3-ab23-da83b0cb09c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6o7fRFkgcSp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01d87807901045ccb7aa3f5e2a8cb603": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034767d9709f46689dda41bd5fc289bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0354a44111b145b28ac3bf5a42cbb572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04c78579ecec4e3288ecee96d06ec600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069cf16fbe814f8c96d033a0c99ce4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c4e19360624925a7a17f25e00c28cd",
            "placeholder": "​",
            "style": "IPY_MODEL_8783d9d51f87488482829d17180de862",
            "value": " 1648877/1648877 [00:00&lt;00:00, 3538079.60it/s]"
          }
        },
        "09a064fdf7f8412c83897b5ce50cf480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e47e6b12c45641ac8c00878f7d9d69c8",
              "IPY_MODEL_86bb5752af754399bde85094a27bf6ba",
              "IPY_MODEL_496ffd7d59b14b00b1d08e7cbff8de5e"
            ],
            "layout": "IPY_MODEL_9eb107a8c452458c9765be1c5e3e0ecb"
          }
        },
        "0a2e0b776f9c49cba579ad2db981ec25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d87807901045ccb7aa3f5e2a8cb603",
            "placeholder": "​",
            "style": "IPY_MODEL_034767d9709f46689dda41bd5fc289bb",
            "value": "100%"
          }
        },
        "0a54912a9edb4b94a0e590e0574cd6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2803911da3449d9a95de19ee7f87c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8348aa10ad7419c9bfa48753a190f90",
            "placeholder": "​",
            "style": "IPY_MODEL_9f29cc9a800c417eb8fbd4c3eb3b6bdd",
            "value": " 28881/28881 [00:00&lt;00:00, 841816.38it/s]"
          }
        },
        "136cdb0e10b34861941d4e3667d5b641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "144f2899607d4fddb5efca2cb174bffd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15999ab899604af49bb053b436da5cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ea4ea8c1bc648738931d614c2884119",
            "placeholder": "​",
            "style": "IPY_MODEL_8cf6ed6ecd9f4560b97b1bbbfbd7cac0",
            "value": " 9912422/9912422 [00:00&lt;00:00, 22678582.83it/s]"
          }
        },
        "169e1f901cc4446589e65d3e18df5c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18804b8466704ac78f2d1ddf9edea1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d54a42d004a4710a5a9b8db21e7d0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6efde7b29bc84cdf8d827c97c4f51e22",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e79b874c2b1471185e8b34f136bc9aa",
            "value": 9912422
          }
        },
        "22eba0a108f24b819bfd87d589db3d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8eca5e10bd4dab95fefde7f7276425",
            "placeholder": "​",
            "style": "IPY_MODEL_136cdb0e10b34861941d4e3667d5b641",
            "value": " 9912422/9912422 [00:00&lt;00:00, 13731961.62it/s]"
          }
        },
        "25cd9bc675694cc1a34a881117fc180c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29824d2c2be44ffaaf84f20d7cb21bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b49c8be38e249789d58b5a276361ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "302642b0ab304e9aad070b8fd9452b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a47e305cce0344fcaa8607f5c0624a22",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f27fdcf26b4438b2c745444717f7e7",
            "value": " 4542/4542 [00:00&lt;00:00, 214716.75it/s]"
          }
        },
        "319ecc66592640649af2f5b59dd92761": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4676af5b099f4b34815eeaaf2ca9e71b",
            "placeholder": "​",
            "style": "IPY_MODEL_d7d2064699754cfc92b3124ebb2ac93b",
            "value": "100%"
          }
        },
        "3a850ff3f58246409301b8f6c3677100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c8eca5e10bd4dab95fefde7f7276425": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40629ce99dfa455986979ad879677692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "424de6e444744e6cace3383f0cee6d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e04fcbb49f4d6a98331fe48f7dc38b",
            "placeholder": "​",
            "style": "IPY_MODEL_fc85af554f774c609ea29f08b2437fe2",
            "value": "100%"
          }
        },
        "42f4224654ad410e8b3d79b58600fa6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ebda24206049689efaf113b6e31f77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e265a7fe894ee88eb10fe2a9869c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_900ba6712f1a4ad78048b8bd47215c2a",
            "placeholder": "​",
            "style": "IPY_MODEL_b6df793da958409b8c3ffcedec69f9b5",
            "value": "100%"
          }
        },
        "4676af5b099f4b34815eeaaf2ca9e71b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48aa3e6d68e044799c7249dd3231785d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "496ffd7d59b14b00b1d08e7cbff8de5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd11904b9d3e4580a1ef69b00f78c56b",
            "placeholder": "​",
            "style": "IPY_MODEL_ae2c070110d04a70871e640b1a418990",
            "value": " 4542/4542 [00:00&lt;00:00, 143507.89it/s]"
          }
        },
        "4d197e4c2f8d424e9403ca5d74c987dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8acc2d78884c09b2ed4b9835f4703e",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3276b4721ca4bfba5e89e9bc6827775",
            "value": 4542
          }
        },
        "4dbdacce56b04a75a64347ba1eaec984": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5199d9fbfb3f4aa68dd0ad1db492c1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dac878b082f4e0cbf160169194ae073",
              "IPY_MODEL_8ebcf3f1b72a4e9cb7d88606aba293a9",
              "IPY_MODEL_069cf16fbe814f8c96d033a0c99ce4f5"
            ],
            "layout": "IPY_MODEL_0a54912a9edb4b94a0e590e0574cd6e3"
          }
        },
        "5705c5c2fc914352a4017fdfa76d479e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45e265a7fe894ee88eb10fe2a9869c32",
              "IPY_MODEL_4d197e4c2f8d424e9403ca5d74c987dd",
              "IPY_MODEL_302642b0ab304e9aad070b8fd9452b7b"
            ],
            "layout": "IPY_MODEL_2b49c8be38e249789d58b5a276361ac8"
          }
        },
        "57301404796e48d6a69a62fd82d1af15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5961e3fa6ae949d6982311db66b59f72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69fc15405fa14df89635a063640cd6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efde7b29bc84cdf8d827c97c4f51e22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8acc2d78884c09b2ed4b9835f4703e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6faadc1431a346e787a9aa6730e95ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72545c70592143788aac27ad4e4e9d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5961e3fa6ae949d6982311db66b59f72",
            "placeholder": "​",
            "style": "IPY_MODEL_40629ce99dfa455986979ad879677692",
            "value": " 1648877/1648877 [00:00&lt;00:00, 17700105.44it/s]"
          }
        },
        "7665f37d9a2d4cd5b96879bef80264f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29824d2c2be44ffaaf84f20d7cb21bdf",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6faadc1431a346e787a9aa6730e95ac7",
            "value": 28881
          }
        },
        "79978348aebb46df88dfe8e1cfbef674": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a36369482144a729bb86728371dfe71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e04fcbb49f4d6a98331fe48f7dc38b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8536e5b9acdf4a9fbeae87e603ff2a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86bb5752af754399bde85094a27bf6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_986254d4384544e79435c73c0d379965",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_169e1f901cc4446589e65d3e18df5c58",
            "value": 4542
          }
        },
        "8783d9d51f87488482829d17180de862": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "886c448eaf3045d2b623f84011b347e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b63ab425f0844a794f9b529c745c4fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69fc15405fa14df89635a063640cd6fb",
            "placeholder": "​",
            "style": "IPY_MODEL_0354a44111b145b28ac3bf5a42cbb572",
            "value": " 28881/28881 [00:00&lt;00:00, 792280.28it/s]"
          }
        },
        "8cf6ed6ecd9f4560b97b1bbbfbd7cac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e79b874c2b1471185e8b34f136bc9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ebcf3f1b72a4e9cb7d88606aba293a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a36369482144a729bb86728371dfe71",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9d340b251c04e5389c4f66abffdc612",
            "value": 1648877
          }
        },
        "900ba6712f1a4ad78048b8bd47215c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986254d4384544e79435c73c0d379965": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa88a0acca94bb1b295ddf49f0a839d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dac878b082f4e0cbf160169194ae073": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dbdacce56b04a75a64347ba1eaec984",
            "placeholder": "​",
            "style": "IPY_MODEL_18804b8466704ac78f2d1ddf9edea1e4",
            "value": "100%"
          }
        },
        "9ea4ea8c1bc648738931d614c2884119": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb107a8c452458c9765be1c5e3e0ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f29cc9a800c417eb8fbd4c3eb3b6bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3276b4721ca4bfba5e89e9bc6827775": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a47e305cce0344fcaa8607f5c0624a22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8348aa10ad7419c9bfa48753a190f90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2c070110d04a70871e640b1a418990": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b197087c66684680a7e45738bba4bd2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6df793da958409b8c3ffcedec69f9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f27fdcf26b4438b2c745444717f7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d340b251c04e5389c4f66abffdc612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba0151714ba74bc98be98935296bd713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_424de6e444744e6cace3383f0cee6d4f",
              "IPY_MODEL_7665f37d9a2d4cd5b96879bef80264f0",
              "IPY_MODEL_8b63ab425f0844a794f9b529c745c4fa"
            ],
            "layout": "IPY_MODEL_04c78579ecec4e3288ecee96d06ec600"
          }
        },
        "bd9049cce1f343daaafc93e5bc7b079b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144f2899607d4fddb5efca2cb174bffd",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48aa3e6d68e044799c7249dd3231785d",
            "value": 9912422
          }
        },
        "bf43cefd0a3343f4aa067a9b90fb52b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b197087c66684680a7e45738bba4bd2b",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e56cfa3c98334b7b82c84fb5c4e6a4d9",
            "value": 1648877
          }
        },
        "c4155f6d259740f4aaee49058bc823fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a2e0b776f9c49cba579ad2db981ec25",
              "IPY_MODEL_1d54a42d004a4710a5a9b8db21e7d0bb",
              "IPY_MODEL_15999ab899604af49bb053b436da5cef"
            ],
            "layout": "IPY_MODEL_25cd9bc675694cc1a34a881117fc180c"
          }
        },
        "c995f27392c3485d8550ca2045c78d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce3756211b854104835290723be6c350",
              "IPY_MODEL_bd9049cce1f343daaafc93e5bc7b079b",
              "IPY_MODEL_22eba0a108f24b819bfd87d589db3d7c"
            ],
            "layout": "IPY_MODEL_dffbc6110aec4251a53904136e27ef60"
          }
        },
        "ca74914a2736480882ddf592e4b9192c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9c2670566b0426788f855a9e2b3cff0",
              "IPY_MODEL_bf43cefd0a3343f4aa067a9b90fb52b3",
              "IPY_MODEL_72545c70592143788aac27ad4e4e9d4a"
            ],
            "layout": "IPY_MODEL_43ebda24206049689efaf113b6e31f77"
          }
        },
        "ce3756211b854104835290723be6c350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79978348aebb46df88dfe8e1cfbef674",
            "placeholder": "​",
            "style": "IPY_MODEL_9aa88a0acca94bb1b295ddf49f0a839d",
            "value": "100%"
          }
        },
        "cf6149624f24416d893b3022dc130851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42f4224654ad410e8b3d79b58600fa6d",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed8475f02b6e4ad1b2cefaa563696101",
            "value": 28881
          }
        },
        "d1370fbe1ae64a77a9bb8c9985a3e83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_319ecc66592640649af2f5b59dd92761",
              "IPY_MODEL_cf6149624f24416d893b3022dc130851",
              "IPY_MODEL_0b2803911da3449d9a95de19ee7f87c8"
            ],
            "layout": "IPY_MODEL_ea1b906035774ed08eb378bd5fca9369"
          }
        },
        "d7d2064699754cfc92b3124ebb2ac93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9c2670566b0426788f855a9e2b3cff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_886c448eaf3045d2b623f84011b347e5",
            "placeholder": "​",
            "style": "IPY_MODEL_3a850ff3f58246409301b8f6c3677100",
            "value": "100%"
          }
        },
        "dffbc6110aec4251a53904136e27ef60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47e6b12c45641ac8c00878f7d9d69c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57301404796e48d6a69a62fd82d1af15",
            "placeholder": "​",
            "style": "IPY_MODEL_8536e5b9acdf4a9fbeae87e603ff2a0b",
            "value": "100%"
          }
        },
        "e56cfa3c98334b7b82c84fb5c4e6a4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea1b906035774ed08eb378bd5fca9369": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8475f02b6e4ad1b2cefaa563696101": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8c4e19360624925a7a17f25e00c28cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc85af554f774c609ea29f08b2437fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd11904b9d3e4580a1ef69b00f78c56b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}